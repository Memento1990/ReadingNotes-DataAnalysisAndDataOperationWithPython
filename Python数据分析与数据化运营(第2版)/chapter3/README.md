# 10 条数据化运营不得不知道的数据预处理经验

## 清洗

1. 主要处理 **缺失值**, **异常值**, **重复值**;
2. 清洗: 对数据集通过丢弃, 填充, 替换, 去重等操作, 达到去除异常, 纠正错误, 不足缺失的目的;

### 数据缺失

1. 行记录的缺失, 即数据记录丢失;
2. 数据列值的缺失;

缺失值状态, 数据库=Null, Python=None, Pandas/Numpy=NaN;

数据列类型缺失值的处理思路:

1. 丢弃, 直接删除带有缺失值的行记录或列字段, 会减少缺失数据记录对总体数据的影响, 但会消减数据特征;
   不宜使用丢弃的场景:
   - 数据集总体中存在大量数据记录不完整的情况且比例较大, 例如超过 10%;
   - 带有缺失值的数据记录大量存在着明显的数据分布规律或特征;
2. 补全
   - 统计法, 数值型数据多采用 均值, 加权均值, 中位数等补全; 分类型数据多采用 类别众数最多的值补全;
   - 模型法, 基于已有的字段, 将缺失字段作为目标变量进行预测;
   - 专家补全
   - 其他方法, 比如随机法, 特殊值法, 多重填补等;
3. 真值转换法
   承认缺失值的存在, 且作为数据分布规律的一部分;
4. 不处理
   KNN, 忽略缺失值, 不参与距离计算;
   决策树及其变体, 将缺失值作为分布的一种状态, 参与建模过程;
   DBSCAN, 不基于距离做计算;

处理思路:

1. 通过一定方法找到缺失值;
2. 分析缺失值在整体样本中的分布占比, 以及缺失值是否具有显著的规律分布特征;
3. 考虑后续是否使用模型填充缺失值, 并决定采用哪种缺失值处理方法;
4. 数据采集阶段可对各个字段设置一个默认值, 在处理数据时注意这部分数据;

### 异常数据

处于特定分布区域或范围之外的数据, 定义为**异常**或**噪音**数据;

- 伪异常, 由于业务特定运营动作产生, 正常反映业务状态;
- 真异常, 不是由于业务动作引起的, 客观反映数据本身分布异常;

无须对异常值做抛弃处理的场景:

1. 异常值正常反映了业务运营结果, 例如促销活动导致的峰值;
2. 异常检测模型, 异常数据本身是目标数据;
3. 包容异常值的数据建模;

### 重复数据

- 数据值完全相同的多条数据记录;
- 数据主体相同但匹配到的唯一属性值不同, 一对多的情况;

谨慎或不建议数据去重场景:

1. 重复记录用于分析演变规律;
2. 重复的记录用于样本不均衡处理; 样本不均衡时会采用对少数样本类别进行简单的过采样, 此时数据中会产生相同记录的多条数据;
3. 重复的记录用于检测业务规则问题

## 分类数据和顺序数据转换为标志变量

**分类数据**: 某些数据属性只能归于某一类别的非数值型数据;
**顺序数据**: 只能归于某一有序类别的非数值型数据;

分类数据和顺序数据要参与模型计算, 通常会转化为数值型数据;

将所有分类或顺序变量的值域从一列多指的形态转换为多列只包含真值的形态;

panda 的 `get_dummies` 方法只会对 `object`, `category` 类型的列做转换;

## 数据降维

降低数据的维度数量

